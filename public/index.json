[{"content":"Ansible As I am aware that this will not be the last time I will rebuild this cluster (I plan setup HA on the controlplane at a later time)I need a way to automate and simplify the cluster rebuild process each time. Enter Ansible. Ansible is an open-source automation tool that simplifies complex IT tasks. Written in Python, it allows you to automate various operations, such as system configuration, software deployment, and workflow orchestration. Ansible’s strengths lie in its simplicity and ease of use, making it a popular choice for managing infrastructure and achieving operational excellence across different platforms\nInstalling Ansible The only dependency that Ansible has is Python installed on your local machine. If you are on a Mac like myself it is fairly simple to install. (I use brew for package management)\nbrew install ansible # Alternatively # pip3 install ansible For other operating systems, its fairly simple to find alternative package managers to get Ansible installed (choco, yum, apt, etc.)\nCreating an Inventory File Ansible will use an inventory file to communicate with my servers. Like a hosts file on your local machine (found at /etc/hosts), which matches IP addresses to domain names. Ansible\u0026rsquo;s inventory file matches the IP addresses I\u0026rsquo;ve configured on my Raspberry Pi\u0026rsquo;s to groups. Hosts file can be either .ini or .yaml, since my inventory is relatively simple I will be using a INI file. For more complex inventories, I would recommend defining your inventory in YAML.\nMy inventory file looks like the following:\n# Control Plane Nodes [controlplane] controlplane1 ansible_host=192.168.1.100 # Worker Nodes [workers] worker1 ansible_host=192.168.1.101 worker2 ansible_host=192.168.1.102 worker3 ansible_host=192.168.1.103 # Group \u0026#39;bramble\u0026#39; with all k3s nodes. [bramble:children] controlplane workers # Variables that will be applied to all [bramble:vars] ansible_ssh_private_key_file=~/.ssh/id_rsa [controlplane] and [workers] are groups that I have defined. [bramble:children] is a group of groups. I defined in each respective line the hostname of the node and the local IP address of the node on my network. Finally I defined a group variable that specifies the desired SSH private key I want Ansible to use when communicating with my nodes. Ad-Hoc Ansible Command Now that I have Ansible installed and created an inventory file, let\u0026rsquo;s just run a command to validate everything is functional.\nansible controlplane -m ping -u chunwu [WARNING]: Platform linux on host cp1 is using the discovered Python interpreter at /usr/bin/python3.11, but future installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible- core/2.17/reference_appendices/interpreter_discovery.html for more information. cp1 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python3.11\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } The ad-hoc command above will ping all nodes in the group controlplane. In my case, since I only have one node specified I only get a response from one node. I also specified my a username of chunwu which is how I configured Raspberry Pi OS when I imaged the SD cards.\nK3s Before I jump into the specific Ansible playbook for my cluster configuration, let\u0026rsquo;s dive into steps if we were to do this manually.\nCGroup Configuration Other guides you may find online will ask you to modify /boot/firmware/cmdline.txt but more recently the file you need to modify is /boot/cmdline.txt. The cmdline.txt file is a configuration file, located in the boot paritition of the SD card on Raspberry Pi, and used to pass additional parameters to the Linux Kernel for the system boot. Read more about cgroups here\n# 1. Open the cmdline.txt file sudo vim /boot/firmware/cmdline.txt #2. Add below into THE END of the current line cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory # 3. Save the file and reboot sudo shutdown -r now Master Node Installation Run the following command to install the K3s master node.\ncurl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\u0026#34;server --disable=traefik --flannel-backend=host-gw --tls-san=192.168.1.85 --bind-address=192.168.1.85 --advertise-address=192.168.1.100 --node-ip=192.168.1.100 --cluster-init\u0026#34; sh -s - There a multitude of ways to configure K3s installation, more details can be found in the documentation. In the command I have specified\u0026hellip;\nserver: This is telling k3s to run in server mode (as opposed to agent mode). In server mode, k3s will start up and manage Kubernetes master components. disable=traefik: This is instructing k3s to disable the Traefik ingress controller. By default, k3s includes and enables Traefik; this flag will prevent that from happening. I plan to install at a later time using Helm. flannel-backend=host-gw: This flag is setting the backend for Flannel (k3s’s default network provider) to use. The host-gw option provides high-performance networking by creating a route for each node in the cluster. tls-san=192.168.1.85: The — tls-san flag allows you to specify additional IP or DNS names that should be included in the TLS certificate that is automatically generated for the Kubernetes API server. You can repeat this flag to add more than one SAN. The value 192.168.1.85 is an additional Subjective Alternative Name (SAN) for the Kubernetes API server’s certificate. bind-address=192.168.1.85: This is the IP address that the k3s API server will listen on. advertise-address=192.168.1.85: This is the IP address that the k3s API server will advertise to other nodes in the cluster. They will use this IP to connect to the API server. node-ip=192.168.1.85: This defines the IP that should be used for Kubernetes services on the nod cluster-init: This flag instructs k3s to initialize a new Kubernetes cluster. If this flag is not provided, k3s will join an existing cluster if one is available. As evolve my configuration I keep this section up to date. Once installed, the k3s configuration should be located in /etc/rancher/k3s/k3s.yaml. I recommend changing the file permissions and creating a k3s configuration file in your ~/.kube/conf.yaml local machine so that you can access your cluster.\nWorker Node Installation To install the worker nodes, we first need to obtain the K3S_TOKEN from the master node. Execute the command shown below to retrieve it:\n# get node-token from master node sudo cat /var/lib/rancher/k3s/server/node-token Upon retrieval of the node token, it is necessary to inject it into the script shown below. This script should be executed on all the Pi nodes specified previously. Please ensure to update the IP address associated with K3S_URL, as required.\n# Execute this to install the nodes curl -sfL https://get.k3s.io | K3S_URL=https://192.168.1.100:6443 \\ K3S_TOKEN=\u0026#34;\u0026lt;token\u0026gt;\u0026#34; sh - That\u0026rsquo;s it your cluster is now configured! But that\u0026rsquo;s an awful a lot of work to repeat manually if wish to ever rebuild your cluster.\nAnsible Playbook The following Ansible playbook will do everything I mentioned above:\n--- - name: Node Preparation become: true hosts: bramble tasks: - name: Ping Host ping: - name: Enable Cgroups lineinfile: path: /boot/firmware/cmdline.txt backrefs: true regexp: \u0026#39;^((?!.*\\bcgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory\\b).*)$\u0026#39; line: \u0026#39;\\1 cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory\u0026#39; notify: - Restart Raspberry Pi handlers: - name: Restart Raspberry Pi reboot: - name: Install k3s on controlplane become: true hosts: controlplane tasks: - name: Ping Host ping: - name: Install K3s on controlplane server shell: \u0026#39;curl -sfL https://get.k3s.io | sh -\u0026#39; - name: Give k3s time to startup agent pause: seconds: 60 - name: Extract K3S_TOKEN from server output command: cat /var/lib/rancher/k3s/server/node-token register: k3s_token failed_when: k3s_token is failed or k3s_token.stdout is undefined - name: Set K3S_Token as a fact set_fact: k3s_token: \u0026#34;{{ k3s_token.stdout }}\u0026#34; - name: Install k3s on workers nodes become: true hosts: workers tasks: - name: Ping hosts ping: - name: Install k3s onto worker nodes shell: curl -sfL https://get.k3s.io | K3S_URL=https://{{ hostvars[\u0026#39;cp1\u0026#39;][\u0026#39;ansible_default_ipv4\u0026#39;].address }}:6443 K3S_TOKEN={{ hostvars[\u0026#39;cp1\u0026#39;][\u0026#39;k3s_token\u0026#39;] }} K3S_NODE_NAME={{ inventory_hostname }} sh - - name: Get k3s kubeconfig become: true hosts: controlplane tasks: - name: Fetch kubeconfig fetch: src: /etc/rancher/k3s/k3s.yaml dest: k3sconfig flat: true You can also refer to my Github repository.\nWhat\u0026rsquo;s Next? There are several different paths I can take with this guide on Part 3, stay tuned!\n","permalink":"http://localhost:1313/posts/kubernetes-on-raspberry-pi-2/","summary":"Ansible As I am aware that this will not be the last time I will rebuild this cluster (I plan setup HA on the controlplane at a later time)I need a way to automate and simplify the cluster rebuild process each time. Enter Ansible. Ansible is an open-source automation tool that simplifies complex IT tasks. Written in Python, it allows you to automate various operations, such as system configuration, software deployment, and workflow orchestration.","title":"Kubernetes on Raspberry Pi - Part 2"},{"content":"Introduction Kubernetes is a powerful open-source platform designed to automate deploying, scaling, and operating application containers. When it comes to running Kubernetes on a Raspberry Pi, there are several lightweight distributions available, with K3s being a popular choice. K3s is specifically designed for resource-constrained environments like IoT devices and edge computing, making it an excellent fit for Raspberry Pi. It offers a simplified installation process, reduced resource requirements, and seamless integration with IoT hardware. There are numerous tutorials and guides available on the internet, here is my detailed approach.\nWhat am I trying to achieve? This is a multi-part series as I build out my home lab. Building it from scratch again and documenting the process will help me create reference documentation and share my knowledge to the world. Another advantage of continually rebuilding it from bottom up again is that I will find opportunities to automate manual tasks such that future rebuilds will be much faster.\nAs I had mentioned previously, there are numerous resources online that may already cover this subject but conclude after the cluster is configured. We will go beyond that and much more, so stay tuned!\nHardware and Cost Everyone has their own budget and certainly there will be trade-offs in the hardware you select but for my home lab this is what I used:\nItem Quantity Price Raspberry Pi 4 8GB Model B 4 75.00 Raspberry Pi PoE+ HAT 4 20.00 SanDisk 32GB Ultra Micro Memory Card 4 7.42 Cat6 Snagless Ethernet Patch Cables (10 Pack) 1 12.99 Ubiquiti Unifi Switch Lite 8 PoE 1 109.00 Ubiquiti Unifi Express 1 149.00 Samsung Fit Plus 256GB USB Hard Drive 3 25.00 Yahboom Raspberry Pi Cluster Case 1 21.00 Total Cost 776.67 Hardware Considerations I thought should share my thoughts and considerations when purchasing the above components\u0026hellip;\nAt the time of purchase the Raspberry Pi 5 was not released yet - I would have went with that option. I purchased the Raspberry Pi\u0026rsquo;s at the tail end of the pandemic so there was a limit on the number of Raspberry Pi\u0026rsquo;s you could purchase due to supply constraints. I wanted to minimize the number of wires and provide for potential future rack mount possibilities so I decided to use PoE to power the Raspberry Pis. I wanted better visibility on my networking so I moved my entire home network to Ubiquiti\u0026rsquo;s Unifi System. I wanted to potentially run stateful workloads on my Kubernetes cluster, hence the Samsung Fit Plus USB Hard Drive\u0026rsquo;s which we will use for persistent volumes. I wanted to 3D print my own cluster case but found a cheap temporary solution in the Yahboom Cluster Case. Eventually I want to run a highly available control plane but due to the limitations of my PoE switch, costs and current needs will leave that for a future update.\nNetwork Topology This is an illustration of the network topology for the planned cluster. The nodes and the router talk to each other via the network switch on a wired connection, while the router serves as a gateway to the Internet via Unifi Express hardwired into Google Fibre.\nSince the cluster is running on a private network, I have full control over the IP addresses of each node. This allows me to control which IP addresses the nodes will be assigned. There are two approaches to do this:\nDHCP Reservations Setting desired IP address in the dhcpd.conf file. I have chosen to do DHCP reservations. If you decide to just modify your dhcpd.conf file if there are other competing devices on the network that already use that IP address then there will be a conflict. Certainly you can do a combination of the two, if you want to know more about how to modify your dhcpd file Tom\u0026rsquo;s Hardware has an excellent guide on how to do this.\nIf you haven\u0026rsquo;t moved over to a Unifi network setup and you are crazy about metrics like I am\u0026hellip; do it! I mean, check this out:\nConfigure Raspberry Pi It\u0026rsquo;s time to flash the OS image in each of the Micro SD cards that have been installed on each Raspberry Pi. For this, you will need Raspberry Pi Imager. To keep things simple for this setup, I will be using Raspberry Pi OS Lite 64 bit. The Lite version of Raspberry PI OS does not include a desktop environment, unlike Raspberry PI OS which has the Pixel desktop environment integrated into that image. Additionally could also use Ubuntu Desktop/Server environment which I may use in the future if when I want to experiment with MicroK8s or KubeADM but for this series we are going to be using K3s\nFlashing the OS At the time of writing, I am using Raspberry Pi Imager v1.8.5. ymmv on the UI as this can change.\nSince this OS variant does not include a desktop environment, SSH will be my primary method for node installation. While username/password is easier and more convenient to use, I prefer to use SSH Keys as they are generally more secure.\nGenerating an SSH Key The following will work on a Macintosh or Linux, for Windows you will need to use a tool like putty.\nssh-keygen -b 2048 -t rsa -C \u0026#34;your_username\u0026#34; -f filename # Example: ssh-keygen -b 2048 -t rsa -C \u0026#34;jsmith\u0026#34; -f vivaglint-yyyymmdd OS Customization To help simplify our setup process we are going to customize the settings in the Pi OS image that will be written to our disk.\nSet the hostname of the node (mine will be: controlplane1, worker1, worker2, worker3) You could set a username and password but I did not as I will configure the node to only allow SSH using a key. Set locale settings And finally we want to take the public key from our key-value pair that we previously generated and set that as the desired method to SSH into our nodes.\nRepeat the above steps for the other Raspberry Pi\u0026rsquo;s. Once I have all the Raspberry Pi\u0026rsquo;s imaged\u0026hellip; I put together the Yahboom cluster case, attached the Raspberry Pi PoE HAT, add the Samsung Fit Plus drives to the worker nodes only.\nYou may want to label your nodes with tape or a label maker, the older you get the easier it is to forget what is what.\nWhat\u0026rsquo;s Next? In the next step we are going to use Ansible to automate the setup of Kubernetes cluster with K3s and go over in detail the settings I will be using to configure the cluster.\n","permalink":"http://localhost:1313/posts/kubernetes-on-raspberry-pi/","summary":"Introduction Kubernetes is a powerful open-source platform designed to automate deploying, scaling, and operating application containers. When it comes to running Kubernetes on a Raspberry Pi, there are several lightweight distributions available, with K3s being a popular choice. K3s is specifically designed for resource-constrained environments like IoT devices and edge computing, making it an excellent fit for Raspberry Pi. It offers a simplified installation process, reduced resource requirements, and seamless integration with IoT hardware.","title":"Kubernetes on Raspberry Pi - Part 1"},{"content":"Let\u0026rsquo;s get started! As I had mentioned in a previous post, my desire is to eventually host everything on my own infrastructure and if time permits try to use a DIY solution. However, given that I want to start sharing my journey from day 0, I need a temporary solution that is reliable, quick to setup, and requires minimal effort. Today, I would like to share how I setup this blog using a static website generator Hugo hosted on Github Pages with a Custom DNS using Cloudflare.\nHugo Hugo is one of the most popular open-source static site generators. I have used it several times in the past for previous iterations of this blog and have found it a my goto choice when I need something quick.\nSince I most likely will not be able to do better job than the [quick-start] guide found on Hugo\u0026rsquo;s documentation site I will be a bit brief in this portion. I started with creating a new repository on Github for this site, aptly named chunwu.dev, and cloned the repository down onto my local machine.\nPlease note that if you decide not to have a custom domain for your site and wish to leverage the default domain that Github provides you must setup your repository name as \u0026lt;user\u0026gt;.github.io. Otherwise your domain will come out as \u0026lt;user\u0026gt;.github.com/\u0026lt;repository-name\u0026gt;, which may not be ideal.\nAfter I had Hugo installed and my Github repository cloned onto my machine, I created my site using the command hugo new site \u0026lt;repository\u0026gt;. Personally, I am a visual person so I start the web server right away with the defaults before I start modifying the site. You can do this by running hugo server -D in the directory of your site.\n*We are using -D to ensure that draft publications are also show locally but when running live we simply use hugo server.\nThere are many places on the web where you can find Hugo themes. However, for today I used https://themes.gohugo.io/ and after brief search I settled on a blog theme called PaperMod.\nI made some quick adjustments to my hugo.toml - a file used you to specify how you want the site. This can be it\u0026rsquo;s own tutorial For now I simply want to enable the theme, so I run echo \u0026quot;theme = PaperMod\u0026quot; \u0026gt;\u0026gt; hugo.toml. (hugo.toml and config.toml are interchangeable)\nYou should now be able to run your website.\nGithub Pages Now that you have a functioning website locally, we commit the code back to your remote repository. We won\u0026rsquo;t dive into the specifics of how to use Github as a Code Versioning System or leveraging Github Actions for CICD, I have implemented Github Actions on my repository to automate deployment This can also be discussed in a future tutorial if there is a desire for it.\nFor now once we have a running website from the previous step, within your working directory. I ran the following commands:\ngit commit . git commit -m \u0026#34;Initial Commit\u0026#34; git push Once your website is in the remote repository\u0026hellip;\nNavigate to the Settings of your repository. On the left menu bar navigate to Pages. For Build and deployment, I have set my source as Github Actions. Go back to your local repository and create a folder called workflows inside a folder called .github Copy and paste the following YAML into a file like main.yaml # Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - master # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.126.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v4 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: # For maximum backward compatibility with Hugo modules HUGO_ENVIRONMENT: production HUGO_ENV: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 Almost there, we need to commit the changes from our local repository to our remote repository. At the root of your local repository:\ngit commit . git commit -m \u0026#34;Added a Github Action\u0026#34; git push If you navigate to your repository on Github and look at the Actions tab you should notice there is a workflow running called Deploy Hugo site to Pages. Once this Github Action runs it\u0026rsquo;s course you should be able to navigate to the domain Github provides you by default, in my case it is: https://cpwu.github.io/chunwu.dev/. When we setup Github Pages, you may have noticed a textbox under Custom domain that you can specify, it really is that simple.\nLet\u0026rsquo;s get a custom domain from Cloudflare\nCloudflare I have used a few domain name registrars in the past but most recently I moved over to Cloudflare. From what I understand, they offer domain registration with no mark-up pricing. However, there is a drawback some tlds may not be available. Luckily for me Cloudflare opened up the ability to purchase .dev domain\u0026rsquo;s last year. If you are not aware .dev must use an SSL certificate in order to load in major browsers. Github will take care if this for us.\nTo purchase a domain, create yourself an account on Cloudflare if you haven\u0026rsquo;t done so already and navigate to Domain Registration.\nUnder Domain Registration navigate to Register Domains. Search for the desired domain name you are looking for. In my case chunwu.dev was available for $10.18 USD. Add an A record for your newly purchased domain by specifying your domain name under Name and 185.199.108.153 for content. You can find the other Github IP addresses for Github pages here Website up! Now that you have your domain name setup, and your website published to Github pages you just need to navigate back to the Settings of your site\u0026rsquo;s Github repository. You should now be able to specify the domain name you purchased with Cloudflare into the textbox and after a few minutes your site will be live on the internet with a custom domain.\nAs previously mentioned, make sure you select the Enforce HTTPS option since this is a requirement for .dev domains and generally a good practice.\n","permalink":"http://localhost:1313/posts/blog-setup/","summary":"Let\u0026rsquo;s get started! As I had mentioned in a previous post, my desire is to eventually host everything on my own infrastructure and if time permits try to use a DIY solution. However, given that I want to start sharing my journey from day 0, I need a temporary solution that is reliable, quick to setup, and requires minimal effort. Today, I would like to share how I setup this blog using a static website generator Hugo hosted on Github Pages with a Custom DNS using Cloudflare.","title":"Custom Domain on Github Pages with Cloudflare"},{"content":"Where have I been? In the previous iteration of this website (there have been many iterations before it). I was running chunwu.dev using Hugo. The site was hosted in Azure Storage and leveraged Azure\u0026rsquo;s Content Delivery Network.\nMy hope was that by having a web presence, it would force me to blog about all the various things I am working on - as they say, you don\u0026rsquo;t understand a topic until you can teach it. With the goal that I would share some knowledge and inspire the next person, as many have done for me. The Problem\u0026hellip; blogging requires time and commitment.\nIn the last 4 years, I have:\nmade a huge pivot in my career. moved to another country. got married. And most recently, my wife and I welcomed our son - Aiden. What am I trying to achieve? My personal goal is to have a miniaturized version of the PaaS (Platform as a Service) environment that I am developing at scale for work. Whenever you work on projects that have the scale that I typically work at, we do not typically get the opportunity to work on all aspects of the platform - as there is just too much to do. Building my homelab would help me understand various technologies in detail and if something breaks, I will at least have an idea how to triage.\nWhat have I done so far? Up to this point, I am running a Kubernetes cluster using 4 Raspberry Pi 4B 8GB. It is configured using one node as the Control Plane and 3 nodes for the data plane. I have a few stateless applications running that have been exposed to the internet using Cloudflare\u0026rsquo;s Zero Trust tunnel, and a monitoring stack using Prometheus, Grafana and Alert Manager.\nIf this all sounds interesting to you, great! The existing infrastructure is a bit janky and is a major motivation for today\u0026rsquo;s post.\nWhat is next? Initially when I completed custom writing a blogging solution using Python and the Flask framework to kick things off, I encountered my first hurdle. Every time I made a breaking change to my homelab the data would be wiped.\nSo, as a temporary solution until my homelab stabilizes, I will be using Hugo once again which I will host using Github Pages made available from my custom DNS.\nStay tuned for weekly posts!\n-Chun\n","permalink":"http://localhost:1313/posts/im-back/","summary":"Where have I been? In the previous iteration of this website (there have been many iterations before it). I was running chunwu.dev using Hugo. The site was hosted in Azure Storage and leveraged Azure\u0026rsquo;s Content Delivery Network.\nMy hope was that by having a web presence, it would force me to blog about all the various things I am working on - as they say, you don\u0026rsquo;t understand a topic until you can teach it.","title":"I am back... again!"}]